{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b68b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85959ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature_to_split=None, threshold=None, left=None, right=None, data=None):\n",
    "        self.feature_to_split = feature_to_split\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6650ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_xgb:\n",
    "    def __init__(self, n_estimators=5, learning_rate=0.1, max_depth=3, min_n_samples=2, lambda_reg=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_n_samples = min_n_samples\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.trees = []\n",
    "        self.base_pred = None\n",
    "\n",
    "\n",
    "    def similarity(self, gradients, hessians):\n",
    "        sum_grads = np.sum(gradients)\n",
    "        sum_hess = np.sum(hessians)\n",
    "        return (sum_grads**2)/(sum_hess + self.lambda_reg)\n",
    "    \n",
    "\n",
    "    def xgb_gain(self, g, h, g_left, h_left, g_right, h_right):\n",
    "        score_root = self.similarity(g, h)\n",
    "        score_left = self.similarity(g_left, h_left)\n",
    "        score_right = self.similarity(g_right, h_right)\n",
    "        return  0.5 * (score_left + score_right - score_root)\n",
    "    \n",
    "\n",
    "    def leaf_weight(self, gradients, hessians):\n",
    "        sum_grads = np.sum(gradients)\n",
    "        sum_hess = np.sum(hessians)\n",
    "        return -sum_grads/(sum_hess + self.lambda_reg)\n",
    "    \n",
    "\n",
    "    def find_best_split(self, X: pd.DataFrame, gradients, hessians):        \n",
    "\n",
    "        # store and update the bests when a better gain is found\n",
    "        best_feature = None\n",
    "        best_gain = -1000\n",
    "        best_threshold = None\n",
    "        best_mask = None\n",
    "\n",
    "        # take a feature, then go through all values of that feature, taking them as the new threshold to check gain\n",
    "        for feature in X.columns: \n",
    "            thresholds = X[feature].unique()\n",
    "            for threshold in thresholds:\n",
    "                # divide into y_left and y_right\n",
    "                mask = (X[feature] <= threshold).values\n",
    "\n",
    "                if sum(mask)==0 or sum(~mask)==0:\n",
    "                    continue\n",
    "\n",
    "                g_left, g_right = gradients[mask], gradients[~mask]\n",
    "                h_left, h_right = hessians[mask], hessians[~mask]\n",
    "\n",
    "\n",
    "                # check gain for the current threshold and feature, and update if a better gain is found\n",
    "                current_gain = self.xgb_gain(gradients, hessians, g_left, h_left, g_right, h_right)\n",
    "\n",
    "                if current_gain > best_gain:\n",
    "                    best_gain = current_gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "                    best_mask = mask\n",
    "            \n",
    "\n",
    "        if best_feature is None:\n",
    "            return None, None, None, None, None, None, None, None\n",
    "\n",
    "\n",
    "        return (best_feature, best_threshold, \n",
    "                X[best_mask], gradients[best_mask], hessians[best_mask],\n",
    "                X[~best_mask], gradients[~best_mask], hessians[~best_mask])\n",
    "    \n",
    "\n",
    "    def build_tree(self, X: pd.DataFrame, gradients, hessians, depth=0):\n",
    "        n_samples, _ = X.shape\n",
    "\n",
    "        # if we satisfy the conditions, we return a leaf node\n",
    "        if depth >= self.max_depth or n_samples < self.min_n_samples:\n",
    "            leaf_value = self.leaf_weight(gradients, hessians)\n",
    "            return Node(data=leaf_value)\n",
    "        \n",
    "        \n",
    "        \n",
    "        best_feature, best_threshold, X_left, g_left, h_left, X_right, g_right, h_right = self.find_best_split(X, gradients, hessians) \n",
    "\n",
    "        # return a leaf node if no gain was found\n",
    "        if best_feature is None:\n",
    "            leaf_value = self.leaf_weight(gradients, hessians)\n",
    "            return Node(data=leaf_value)\n",
    "\n",
    "\n",
    "        left_child = self.build_tree(X_left, g_left, h_left, depth+1)\n",
    "        right_child = self.build_tree(X_right, g_right, h_right, depth+1)\n",
    "\n",
    "        return Node(feature_to_split=best_feature, threshold=best_threshold, left=left_child, right=right_child)\n",
    "\n",
    "\n",
    "    def predict_tree(self, node, X):\n",
    "        predictions = []\n",
    "        for i in range(len(X)):\n",
    "            row = X.iloc[i]\n",
    "            current = node\n",
    "\n",
    "            while current.data is None:\n",
    "                if row[current.feature_to_split] <= current.threshold:\n",
    "                    current = current.left\n",
    "                else:\n",
    "                    current = current.right\n",
    "            predictions.append(current.data)\n",
    "\n",
    "        return np.array(predictions)\n",
    "        \n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.base_pred = np.mean(y)\n",
    "        y_pred = np.full(len(y), self.base_pred)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            gradients = y_pred - y\n",
    "            hessians = np.ones(len(y))\n",
    "\n",
    "            tree = self.build_tree(X, gradients, hessians, depth=0)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "            update_values = self.predict_tree(tree, X)\n",
    "            y_pred += self.learning_rate*update_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        final_predictions = np.full(len(X), self.base_pred)\n",
    "\n",
    "\n",
    "        for tree in self.trees:\n",
    "            final_predictions += self.learning_rate*self.predict_tree(tree, X)\n",
    "\n",
    "        return final_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdf984a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>S</th>\n",
       "      <th>PR1</th>\n",
       "      <th>PR2</th>\n",
       "      <th>S$_{BET}$</th>\n",
       "      <th>H$_2$/CO$_2$</th>\n",
       "      <th>GHSV</th>\n",
       "      <th>MC</th>\n",
       "      <th>P</th>\n",
       "      <th>T</th>\n",
       "      <th>CT</th>\n",
       "      <th>CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.4</td>\n",
       "      <td>88.6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>115500.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>623</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.4</td>\n",
       "      <td>88.6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>94500.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>623</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.5</td>\n",
       "      <td>60.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>573</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>88.6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>115500.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>623</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.5</td>\n",
       "      <td>60.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>773</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>67.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>623</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>67.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>623</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>67.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>623</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>67.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>623</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>773</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1234 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          M     S  PR1  PR2  S$_{BET}$  H$_2$/CO$_2$      GHSV    MC    P  \\\n",
       "0       4.4  88.6  6.8  0.2        9.0          10.0  115500.0  0.50  6.0   \n",
       "1       4.4  88.6  6.8  0.2        9.0           8.0   94500.0  0.50  6.0   \n",
       "2      36.5  60.8  2.7  0.0      218.0           3.0  120000.0  0.02  4.0   \n",
       "3       4.4  88.6  6.8  0.2        9.0          10.0  115500.0  0.50  4.0   \n",
       "4      36.5  60.8  2.7  0.0      218.0           3.0   60000.0  0.04  4.0   \n",
       "...     ...   ...  ...  ...        ...           ...       ...   ...  ...   \n",
       "1229   67.0  33.0  0.0  0.0       96.0           4.0   24000.0  0.10  4.0   \n",
       "1230   67.0  33.0  0.0  0.0       96.0           4.0   42000.0  0.10  4.0   \n",
       "1231   67.0  33.0  0.0  0.0       96.0           4.0   42000.0  0.10  4.0   \n",
       "1232   67.0  33.0  0.0  0.0       96.0           3.0   24000.0  0.10  3.0   \n",
       "1233  100.0   0.0  0.0  0.0       42.0           3.0   19200.0   NaN  3.0   \n",
       "\n",
       "          T   CT   CD  \n",
       "0     598.0  623  2.0  \n",
       "1     598.0  623  2.0  \n",
       "2     453.0  573  4.0  \n",
       "3     598.0  623  2.0  \n",
       "4     453.0  773  5.0  \n",
       "...     ...  ...  ...  \n",
       "1229  473.0  623  3.0  \n",
       "1230  493.0  623  3.0  \n",
       "1231  513.0  623  3.0  \n",
       "1232  513.0  623  3.0  \n",
       "1233  543.0  773  4.0  \n",
       "\n",
       "[1234 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preprocessing steps from previous notebook\n",
    "df = pd.read_excel(\"./Curated_data_1234_datapoints.xlsx\")\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.drop(columns=[\"Reference DOI\", \"Unnamed: 23\"], axis=1)\n",
    "df['Support Loading [wt.%]'] = 100 - df['Metal Loading [wt.%]'] - df['Promoter 1 loading [wt.%]'] - df['Promoter 2 loading [wt.%]']\n",
    "\n",
    "y = df.iloc[:, 0]\n",
    "y = y/1000  #units aren't consistent\n",
    "\n",
    "X = df[[\"Metal Loading [wt.%]\", \"Support Loading [wt.%]\", \"Promoter 1 loading [wt.%]\", \"Promoter 2 loading [wt.%]\", \"SBET [m2 g-1]\", \"H2/CO2 [-]\", \"GHSV [cm3 h-1 gcat-1]\", \"Catalyst amount [g]\", \"Pressure [Mpa]\", \"Temperature [K]\", \"Calcination Temperature [K]\", \"Calcination duration [h]\"]]\n",
    "\n",
    "# rename the columns\n",
    "column_names = [\"M\", \"S\", \"PR1\", \"PR2\", \"S$_{BET}$\", \"H$_2$/CO$_2$\", \"GHSV\", \"MC\", \"P\", \"T\", \"CT\", \"CD\"]\n",
    "X.columns = column_names\n",
    "\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23198901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Custom XGBoost...\n",
      "Done!\n",
      "Custom XGB RMSE: 0.10562755619213582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8400705813265509"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.15, random_state=10)\n",
    "\n",
    "\n",
    "my_xgb = Custom_xgb(n_estimators=30, max_depth=8, learning_rate=0.2, lambda_reg=1)\n",
    "\n",
    "\n",
    "print(\"Training Custom XGBoost...\")\n",
    "my_xgb.fit(X_train, y_train) \n",
    "print(\"Done!\")\n",
    "\n",
    "preds = my_xgb.predict(X_test)\n",
    "rmse = np.sqrt(sklearn.metrics.mean_squared_error(y_test, preds))\n",
    "print(f\"Custom XGB RMSE: {rmse}\")\n",
    "\n",
    "sklearn.metrics.r2_score(y_test, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
