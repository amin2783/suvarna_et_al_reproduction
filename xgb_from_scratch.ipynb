{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85959ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature_to_split=None, threshold=None, left=None, right=None, data=None):\n",
    "        self.feature_to_split = feature_to_split\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6650ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_xgb:\n",
    "    def __init__(self, max_depth=3, min_n_samples=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_n_samples = min_n_samples\n",
    "        self.root = None\n",
    "\n",
    "    def gain_variance(self, y: pd.DataFrame, y_left: pd.DataFrame, y_right: pd.DataFrame):\n",
    "        y_var = np.var(y)\n",
    "        y_left_var = np.var(y_left)\n",
    "        y_right_var = np.var(y_right)\n",
    "\n",
    "        weighted_var = (len(y_left)*y_left_var + len(y_right)*y_right_var)/len(y)\n",
    "\n",
    "        return (y_var - weighted_var)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def find_best_split(self, X: pd.DataFrame, y: pd.DataFrame):        \n",
    "\n",
    "        # store and update the bests when a better gain is found\n",
    "        best_feature = None\n",
    "        best_gain = -1000\n",
    "        best_threshold = None\n",
    "        best_mask = None\n",
    "\n",
    "        # take a feature, then go through all values of that feature, taking them as the new threshold to check gain\n",
    "        for feature in X.columns: \n",
    "            thresholds = X[feature].unique()\n",
    "            for threshold in thresholds:\n",
    "                # divide into y_left and y_right\n",
    "                mask = X[feature] <= threshold\n",
    "                y_left = y[mask]\n",
    "                y_right = y[~mask]\n",
    "\n",
    "                if len(y_left)==0 or len(y_right)==0:\n",
    "                    continue\n",
    "\n",
    "                # check gain for the current threshold and feature, and update if a better gain is found\n",
    "                current_gain = self.gain_variance(y, y_left, y_right)\n",
    "                if current_gain > best_gain:\n",
    "                    best_gain = current_gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "                    best_mask = mask\n",
    "            \n",
    "\n",
    "        if best_feature is None:\n",
    "            return None, None, None, None, None, None\n",
    "        \n",
    "\n",
    "        # construct the x_left, y_left, x_right, y_right according to the best feature and threshold\n",
    "        X_left = X[best_mask]\n",
    "        X_right = X[~best_mask]\n",
    "        \n",
    "        y_left = y[best_mask]\n",
    "        y_right = y[~best_mask]\n",
    "\n",
    "\n",
    "\n",
    "        return (best_feature, best_threshold, X_left, y_left, X_right, y_right)\n",
    "    \n",
    "\n",
    "    def build_tree(self, X: pd.DataFrame, y: pd.DataFrame, depth=0):\n",
    "        n_samples, _ = X.shape\n",
    "\n",
    "        # if we satisfy the conditions, we return a leaf node\n",
    "        if depth >= self.max_depth or n_samples < self.min_n_samples:\n",
    "            leaf_mean = np.mean(y)\n",
    "            return Node(data=leaf_mean)\n",
    "        \n",
    "        \n",
    "        \n",
    "        best_feature, best_threshold, X_left, y_left, X_right, y_right = self.find_best_split(X, y) \n",
    "\n",
    "        # return a leaf node if no gain was found\n",
    "        if best_feature is None:\n",
    "            leaf_mean = np.mean(y)\n",
    "            return Node(data=leaf_mean)\n",
    "\n",
    "\n",
    "        left_child = self.build_tree(X_left, y_left, depth+1)\n",
    "        right_child = self.build_tree(X_right, y_right, depth+1)\n",
    "\n",
    "        return Node(feature_to_split=best_feature, threshold=best_threshold, left=left_child, right=right_child)\n",
    "\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self.build_tree(X, y)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "\n",
    "        for row_i in range(len(X)):\n",
    "            row = X.iloc[row_i]\n",
    "\n",
    "            current_node = self.root\n",
    "\n",
    "            while current_node.data is None:\n",
    "                feature = current_node.feature_to_split\n",
    "                threshold = current_node.threshold\n",
    "                \n",
    "                \n",
    "                if row[feature] <= threshold:\n",
    "                    current_node = current_node.left\n",
    "                else:\n",
    "                    current_node = current_node.right\n",
    "\n",
    "            predictions.append(current_node.data)\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # gains = dict()\n",
    "        # max_gain = 0\n",
    "\n",
    "        # # for categorical data. OHE only\n",
    "        # for feature in X.columns:\n",
    "        #     for row in range(len(X)):\n",
    "        #         if X[row][feature]:\n",
    "        #             pd.concat([y_left, y[row]])\n",
    "        #         else:\n",
    "        #             pd.concat([y_right, y[row]])\n",
    "\n",
    "        #     current_gain = self.gain_variance(y, y_left, y_right)\n",
    "\n",
    "        #     if current_gain > max_gain:\n",
    "        #         max_gain = current_gain\n",
    "            \n",
    "        #     gains[str(current_gain)] = feature\n",
    "\n",
    "        # feature_to_split = gains[str(max_gain)]\n",
    "\n",
    "\n",
    "        # X_left = pd.DataFrame()\n",
    "        # X_left.columns = X.columns\n",
    "        # X_right = pd.DataFrame()\n",
    "        # X_right.columns = X.columns\n",
    "\n",
    "\n",
    "        # for row in range(len(X)):\n",
    "        #     if X[row][feature_to_split]:\n",
    "        #         pd.concat([X_left, X[row]])\n",
    "        #     else:\n",
    "        #         pd.concat([X_right, X[row]])\n",
    "\n",
    "        \n",
    "        # for continuous (will later delete the above categorical)\n",
    "\n",
    "\n",
    "        # ---------------------------------------------\n",
    "\n",
    "    # def entropy(self, X: pd.DataFrame, feature: str):\n",
    "    #     successes = np.sum(X[feature])\n",
    "\n",
    "    #     if successes == 0 or successes == len(X):\n",
    "    #         return 1\n",
    "        \n",
    "    #     else:\n",
    "    #         p1 = np.sum(X[feature])/len(X)\n",
    "    #         p2 = 1-p1\n",
    "    #         return -p1*np.log2(p1) - p2*np.log2(p2)\n",
    "\n",
    "\n",
    "\n",
    "    # def gain_entropy(self, X: pd.DataFrame, X_left: pd.DataFrame, X_right: pd.DataFrame, feature: str):\n",
    "    #     x_entropy = self.entropy(X, feature)\n",
    "    #     x_left_entropy = self.entropy(X_left, feature)\n",
    "    #     x_right_entropy = self.entropy(X_right, feature)\n",
    "\n",
    "    #     weighted_entropy = len(X_left)*x_left_entropy + len(X_right)*x_right_entropy\n",
    "\n",
    "    #     return (x_entropy - weighted_entropy)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
